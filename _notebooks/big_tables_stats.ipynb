{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f5f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Duplikat-Statistiken:\n",
      "5 Transaktionen aus Datei transactions_1_1.xlsx sind in Datei transactions_1_2.xlsx dupliziert (entsprechen 50.00% der Transaktionen in Datei transactions_1_2.xlsx).\n",
      "4 Transaktionen aus Datei transactions_1_1.xlsx sind in Datei transactions_1_3.xlsx dupliziert (entsprechen 40.00% der Transaktionen in Datei transactions_1_3.xlsx).\n",
      "1 Transaktionen aus Datei transactions_1_1.xlsx sind in Datei transactions_1_5.xlsx dupliziert (entsprechen 10.00% der Transaktionen in Datei transactions_1_5.xlsx).\n",
      "1 Transaktionen aus Datei transactions_1_3.xlsx sind in Datei transactions_1_5.xlsx dupliziert (entsprechen 10.00% der Transaktionen in Datei transactions_1_5.xlsx).\n",
      "\n",
      "Globale Duplikat-Statistiken pro Datei:\n",
      "In Datei transactions_1_1.xlsx sind 5 von 10 Transaktionen (50.00%) dupliziert. Diese erscheinen auch in: transactions_1_2.xlsx, transactions_1_3.xlsx, transactions_1_5.xlsx.\n",
      "In Datei transactions_1_2.xlsx sind 5 von 10 Transaktionen (50.00%) dupliziert. Diese erscheinen auch in: transactions_1_1.xlsx, transactions_1_3.xlsx, transactions_1_5.xlsx.\n",
      "In Datei transactions_1_3.xlsx sind 5 von 10 Transaktionen (50.00%) dupliziert. Diese erscheinen auch in: transactions_1_1.xlsx, transactions_1_2.xlsx, transactions_1_5.xlsx.\n",
      "In Datei transactions_1_4.xlsx sind 0 von 10 Transaktionen (0.00%) dupliziert. Diese erscheinen auch in: keine.\n",
      "In Datei transactions_1_5.xlsx sind 2 von 10 Transaktionen (20.00%) dupliziert. Diese erscheinen auch in: transactions_1_1.xlsx, transactions_1_2.xlsx, transactions_1_3.xlsx.\n",
      "In Datei transactions_1_6.xlsx sind 0 von 10 Transaktionen (0.00%) dupliziert. Diese erscheinen auch in: keine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def read_all_files(directory):\n",
    "    \"\"\"\n",
    "    Liest alle Excel-Dateien im Verzeichnis \"Indikatoren\" ein und gibt ein Dictionary zurück:\n",
    "       {Dateipfad: DataFrame}\n",
    "    Der DataFrame wird aus dem Blatt \"Transaktionen zum Indiztreffer\" erstellt.\n",
    "    \"\"\"\n",
    "    file_pattern = os.path.join(directory, \"*.xlsx\")\n",
    "    files = glob.glob(file_pattern)\n",
    "    data = {}\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_excel(f, sheet_name=\"Transaktionen zum Indiztreffer\", engine=\"openpyxl\")\n",
    "            data[f] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Lesen der Datei {f}: {e}\")\n",
    "    return data\n",
    "\n",
    "def add_dup_keys(data):\n",
    "    \"\"\"\n",
    "    Fügt jedem DataFrame im Dictionary 'data' eine neue Spalte 'dup_key' hinzu.\n",
    "    Die Spalte 'dup_key' wird als Tuple aus den Spalten \n",
    "          'Kontonr.', 'Kundennr.', 'Transaktionstyp', 'Buchungstag'\n",
    "    gebildet und dient als Schlüssel zur Duplikat-Erkennung.\n",
    "    \"\"\"\n",
    "    for df in data.values():\n",
    "        if 'dup_key' not in df.columns:\n",
    "            df['dup_key'] = df[['Kontonr.', 'Kundennr.', 'Transaktionstyp', 'Buchungstag']]\\\n",
    "                            .astype(str)\\\n",
    "                            .agg(tuple, axis=1)\n",
    "\n",
    "def build_global_mapping(data):\n",
    "    \"\"\"\n",
    "    Baut ein globales Mapping: Für jeden 'dup_key' wird als Wert eine Menge erstellt, \n",
    "    die alle Dateinamen (vollständige Pfade) enthält, in denen dieser Schlüssel vorkommt.\n",
    "    Rückgabe: {dup_key: set(Dateinamen)}\n",
    "    \"\"\"\n",
    "    global_mapping = {}\n",
    "    for filename, df in data.items():\n",
    "        # Nutze die bereits erzeugte Spalte 'dup_key'\n",
    "        for key in df['dup_key'].unique():\n",
    "            if key not in global_mapping:\n",
    "                global_mapping[key] = set()\n",
    "            global_mapping[key].add(filename)\n",
    "    return global_mapping\n",
    "\n",
    "def analyze_pairwise_duplicates(data, global_mapping):\n",
    "    \"\"\"\n",
    "    Für jeden dup_key, der in mehr als einer Datei vorkommt,\n",
    "    wird angenommen, dass die Datei mit der niedrigsten Nummer als Original (Quelle) gilt.\n",
    "    Es werden pairwise-Duplikate gezählt, also:\n",
    "       {Quelle: {Zieldatei: duplicate_count, ...}, ...}\n",
    "    \"\"\"\n",
    "    def extract_index(fname):\n",
    "        base = os.path.basename(fname)\n",
    "        parts = base.split('_')\n",
    "        try:\n",
    "            num_str = parts[-1].replace(\".xlsx\", \"\")\n",
    "            return int(num_str)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    \n",
    "    duplicates = {}\n",
    "    for key, files in global_mapping.items():\n",
    "        if len(files) > 1:\n",
    "            sorted_files = sorted(files, key=extract_index)\n",
    "            source_file = sorted_files[0]\n",
    "            for dest_file in sorted_files[1:]:\n",
    "                # Zähle die Vorkommen von key in der Zieldatei\n",
    "                dest_count = data[dest_file]['dup_key'].value_counts().get(key, 0)\n",
    "                duplicates.setdefault(source_file, {}).setdefault(dest_file, 0)\n",
    "                duplicates[source_file][dest_file] += dest_count\n",
    "    return duplicates\n",
    "\n",
    "def compute_global_file_stats(data, global_mapping):\n",
    "    \"\"\"\n",
    "    Berechnet für jede Datei, wie viele Zeilen (Transaktionen) dupliziert sind, \n",
    "    also in mindestens einer anderen Datei vorkommen.\n",
    "    \n",
    "    Rückgabe ist ein Dictionary:\n",
    "      { Dateipfad: { 'duplicate_count': X, 'total': Y, 'percentage': Z, 'other_files': [Liste] } }\n",
    "    \"\"\"\n",
    "    file_stats = {}\n",
    "    for filename, df in data.items():\n",
    "        total = len(df)\n",
    "        # Markiere jede Zeile als Duplikat, wenn ihr dup_key in einer anderen Datei vorkommt\n",
    "        is_dup = df['dup_key'].apply(lambda key: len(global_mapping.get(key, set())) > 1)\n",
    "        duplicate_count = is_dup.sum()\n",
    "        # Sammle für diese duplizierten Zeilen alle anderen Dateien, in denen derselbe Schlüssel vorkommt.\n",
    "        other_files = set()\n",
    "        for key in df.loc[is_dup, 'dup_key']:\n",
    "            other_files.update(global_mapping.get(key, set()) - {filename})\n",
    "        file_stats[filename] = {\n",
    "            'duplicate_count': duplicate_count,\n",
    "            'total': total,\n",
    "            'percentage': (duplicate_count / total * 100) if total > 0 else 0,\n",
    "            'other_files': sorted(list(other_files))\n",
    "        }\n",
    "    return file_stats\n",
    "\n",
    "def print_pairwise_statistics(duplicates, data):\n",
    "    \"\"\"\n",
    "    Gibt die pairwise Duplikat-Statistiken aus:\n",
    "    \"X Transaktionen aus Datei [Quelle] sind in Datei [Ziel] dupliziert (entsprechen Y% der Transaktionen in Datei [Ziel]).\"\n",
    "    \"\"\"\n",
    "    print(\"Pairwise Duplikat-Statistiken:\")\n",
    "    for source, dest_dict in duplicates.items():\n",
    "        source_name = os.path.basename(source)\n",
    "        for dest, dup_count in dest_dict.items():\n",
    "            dest_name = os.path.basename(dest)\n",
    "            total_dest = len(data[dest])\n",
    "            percentage = (dup_count / total_dest * 100) if total_dest > 0 else 0\n",
    "            print(f\"{dup_count} Transaktionen aus Datei {source_name} sind in Datei {dest_name} dupliziert \"\n",
    "                  f\"(entsprechen {percentage:.2f}% der Transaktionen in Datei {dest_name}).\")\n",
    "    print()\n",
    "\n",
    "def print_global_file_statistics(file_stats):\n",
    "    \"\"\"\n",
    "    Gibt für jede Datei aus, wie viele ihrer Transaktionen dupliziert sind:\n",
    "    \"In Datei [X] sind Y von Z Transaktionen ({P}%) dupliziert. Diese erscheinen auch in: Datei A, Datei B, ...\".\n",
    "    \"\"\"\n",
    "    print(\"Globale Duplikat-Statistiken pro Datei:\")\n",
    "    for filename, stats in file_stats.items():\n",
    "        base_name = os.path.basename(filename)\n",
    "        dup_count = stats['duplicate_count']\n",
    "        total = stats['total']\n",
    "        percentage = stats['percentage']\n",
    "        other_files = [os.path.basename(f) for f in stats['other_files']]\n",
    "        others_str = \", \".join(other_files) if other_files else \"keine\"\n",
    "        print(f\"In Datei {base_name} sind {dup_count} von {total} Transaktionen ({percentage:.2f}%) dupliziert. \"\n",
    "              f\"Diese erscheinen auch in: {others_str}.\")\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    directory = \"Indikatoren\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Verzeichnis {directory} existiert nicht.\")\n",
    "        return\n",
    "\n",
    "    data = read_all_files(directory)\n",
    "    if not data:\n",
    "        print(\"Keine Dateien gefunden oder keine Daten zum Verarbeiten.\")\n",
    "        return\n",
    "\n",
    "    # Ergänze die DataFrames um den Duplikatschlüssel\n",
    "    add_dup_keys(data)\n",
    "    # Erstelle ein globales Mapping: dup_key -> Menge der Dateien\n",
    "    global_mapping = build_global_mapping(data)\n",
    "    # Berechne pairwise-Duplikate: Quelle -> Ziel -> Anzahl\n",
    "    duplicates = analyze_pairwise_duplicates(data, global_mapping)\n",
    "    # Berechne globale Duplikat-Statistiken pro Datei\n",
    "    file_stats = compute_global_file_stats(data, global_mapping)\n",
    "    \n",
    "    # Ausgabe der Statistiken (auf Deutsch)\n",
    "    print_pairwise_statistics(duplicates, data)\n",
    "    print_global_file_statistics(file_stats)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
